# ChatGLM3-6B QLoRA 微调与数据集对比实验

本项目基于 [DjangoPeng/LLM-quickstart](https://github.com/DjangoPeng/LLM-quickstart) 的 QLoRA 微调流程，对 **ChatGLM3-6B** 模型进行多轮不同数据集的训练与推理对比，探索数据集质量与模型效果之间的关系。

## 📂 项目结构

```
.
├── 01_qlora_chatglm3_timestamp.ipynb                            # 第一次微调
├── 01_qlora_chatglm3_timestamp-error-dataset.ipynb              # 使用错误数据集微调
├── 01_qlora_chatglm3_timestamp-lizhe-dataset-overfit.ipynb      # 过拟合训练
├── 02_chatglm_inference.ipynb                                   # 模型推理与对比
├── 03_gen_dataset_deepseek.ipynb                                # 使用 Deepseek 生成新数据集
├── gen_dataset_deepseek.py                                      # 使用 Deepseek 生成新数据集的python文件
├── data/
│   ├── zhouyi_dataset_20240118_163659.csv
│   ├── zhouyi_dataset_20240118_163659_content_error.csv
│   └── zhouyi_train_dataset_lizhe.csv
└── README.md
```

---

## 🧪 实验流程与设计思路

通过系统地学习老师的作业描述，我们理解到本次作业的目的是对 ChatGLM3-6B 模型进行多轮 QLoRA 微调，系统性地探究数据集质量对模型训练效果和推理表现的影响。

老师设计的整体流程如下：

1. **基准训练**  
   使用老师提供的标准数据集作为训练基准，通过少量训练轮次快速获得基础微调模型，建立性能参考点。

2. **错误数据集训练**  
   通过人为打乱数据集中的回答部分，构造带有“噪声”的错误数据，模拟现实中数据质量参差不齐的情况，检验模型对错误标签的鲁棒性及其训练表现。

3. **过拟合实验**  
   利用 Openai 生成的高度一致性数据集，在较大训练轮次下刻意过拟合模型，观察模型对训练数据的记忆能力及泛化能力的变化。

4. **推理与对比**  
   统一输入测试用例，依次加载上述不同训练版本模型，进行推理输出比对，直观展示数据质量和训练策略对模型性能的影响。

---

### 设计理念

- **数据驱动**：重点分析数据集质量（准确性、一致性）对微调效果的决定性作用。  
- **对比验证**：通过相同模型架构与训练参数，变化数据输入，确保实验对比的公平性和结果的可解释性。  
- **实用性导向**：通过过拟合实验探索极端训练状态下模型表现，为后续模型调优和数据清洗提供参考依据。


---

## 🚀 实验步骤

### **第一步：基准训练**
参考微调代码：  
[qlora_chatglm3_timestamp.ipynb](https://github.com/DjangoPeng/LLM-quickstart/blob/main/chatglm/qlora_chatglm3_timestamp.ipynb)

- 数据集：`zhouyi_dataset_20240118_163659.csv`（老师提供）
- 训练脚本：`01_qlora_chatglm3_timestamp.ipynb`
- 训练轮数：3
- 输出模型：  
  ```
  chatglm3-6b-epoch3-20250808_233529
  ```

---

### **第二步：错误数据集训练**
- 数据集：  
  将原有数据集中的 **回答** 打乱生成错误版本  
  `zhouyi_dataset_20240118_163659_content_error.csv`
- 训练脚本：`01_qlora_chatglm3_timestamp-error-dataset.ipynb`
- 输出模型：  
  ```
  chatglm3-6b-epoch3-20250809_002946-error-dataset
  ```

---

### **第三步：过拟合实验**
- 数据集生成：  
  使用 `03_gen_dataset_deepseek.ipynb` 调用 Deepseek API 生成新数据集  
  `zhouyi_train_dataset_lizhe.csv`
- 训练脚本：`01_qlora_chatglm3_timestamp-lizhe-dataset-overfit.ipynb`
- 训练轮数：50（过拟合）
- 输出模型：  
  ```
  chatglm3-6b-epoch50-20250809_015451-lizhe
  ```

---

### **第四步：推理与对比**
- 推理脚本：`02_chatglm_inference.ipynb`
- 功能：加载不同版本的模型，使用相同输入进行推理，并输出对比结果

---
### 📊 **模型对比结果示例**

| 输入问题 | 基准模型输出 | 错误数据集模型输出 | 过拟合模型输出 |
| --- | --- | --- | --- |
| 解释下乾卦是什么？ | 原文："乾卦是《周易》中一个充满象征意义的卦象，由下卦坤（地）和上卦乾（天）组成。这一卦象生动地描绘了天地之间的景象，乾卦象征着天地的运行与秩序，坤卦则代表大地的包容与承载。乾卦的卦象 features天'（一）向上生长，象征万物递进成长，体现了宇宙间合理的自然规律。"  <br><br>内容详尽，展现了卦象的构成与象征，语言较为流畅，但“features天’（一）向上生长”表述稍显不自然。整体描述契合传统哲学含义。 | 原文："在周易中，屯卦是一个大吉大利的卦象，预示着吉祥和大利。然而，不利于出门，但有利于建国封侯。屯卦由上卦坎（水）下卦震（雷）组成，坎为云，震为雷。预示着云行雷动的卦象。"  <br><br>内容错误，将乾卦与屯卦混淆，卦象及象征意义与题目无关，显示数据集存在较大偏差。 | 原文："乾卦是周易中一个充满力量和象征的卦象，由下卦坤（地）和上卦乾（天）组成。这一卦象生动地描绘了'天行健'的哲学内涵，即宇宙中天气运行的方式，象征着宇宙的运行力量和秩序。乾卦的核心象征意义是'键开键关'，这代表了掌握事物发展的关键能力。"  <br><br>阐述丰富且带有哲学视角，注重辩证与应用，但部分术语不够准确，影响表达严谨性。 |
| 地水师卦是什么？ | 原文："地水师卦是一个富有哲学意义的卦象，由下卦地（乾）和上卦水（兑）组成。这一卦象生动地展现了'泽无名义'的哲学思想，即大地看似没有名字，却有着丰富的生命力和自然美。"  <br><br>描述内容较为抽象，体现了哲学意味，但“地（乾）”及“水（兑）”的组合表述存在偏差，需更准确的卦象对应。 | 原文："蒙卦是由艮卦（山）下，坎卦（水）上组成的异卦相叠。它代表着通泰，启蒙的意义。在这里，卜者并非是在向幼稚愚昧的人取求，而是幼稚愚昧的人在向卜者求教。"  <br><br>错误内容，混淆了地水师卦与蒙卦，卦象及象征意义完全不符，明显数据错误。 | 原文："地水师卦 在周易哲学体系中，地水师卦是一个富有深邃智慧的卦象，由下卦地（乾）和上卦水（坤）组成。这一卦象生动地描绘了'地生水'的自然景象，象征着事物在发展过程中必然产生的先后顺序关系。在卦象构成上，乾卦代表天，坤卦代表地，二者结合形成天地的基础关系。"  <br><br>内容详细，融入哲学解读，表达较清晰，但卦象组合描述与传统略有不符，需注意术语准确性。 |
| 周易中的讼卦是什么？ | 原文："讼卦是《周易》中一个充满争议和争端的卦象，由乾（天）下卦与坤（地）上卦组成。乾卦代表天，象征刚健，坤卦代表地，象征柔顺。该卦的卦序为'下天柔以济天下刚'，生动地描绘了天地的交融与运行。"  <br><br>表达清晰，但卦象构成与传统不同，部分术语混淆，需纠正乾坤上下卦顺序及其象征。 | 原文："周易中的讼卦是什么概念 坤卦，是周易中的一卦，由两个坤卦叠加而成，代表大地的顺从和承载。"  <br><br>错误严重，混淆讼卦与坤卦，内容与题意不符，反映数据集错误。 | 原文："讼卦 在周易哲学体系中，讼卦是一个充满辩证智慧的卦象，由上卦乾（天）和下卦坎（水）组成。天向西转，水往东流，两者运行方向相背，生动地象征着人世间的争讼与矛盾。这一卦象深刻揭示了人类社会关系中不可避免的纠纷现象。"  <br><br>阐述哲学性强，结合现代视角，表达深刻，但卦象构成描述需更符合传统经典。 |




---

## 💡 总结
1. **数据集质量直接决定模型效果**：错误数据集训练的模型在多数情况下无法给出合理回答。  
2. **过拟合会导致泛化能力下降**：虽然训练集上的表现极好，但对未见过的问题表现较差。  
3. **基准模型在泛化与稳定性上更均衡**。
4. **gen_dataset_deepseek.py** 是转换成python后的文件


