{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea8071b6-0ca8-435e-ac3e-5aac5e62dada",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.36.2\n",
      "Uninstalling transformers-4.36.2:\n",
      "  Successfully uninstalled transformers-4.36.2\n",
      "Found existing installation: accelerate 0.25.0\n",
      "Uninstalling accelerate-0.25.0:\n",
      "  Successfully uninstalled accelerate-0.25.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbd6a4a2-8bd7-4675-a5da-5625037a3128",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting transformers==4.36.2\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/20/0a/739426a81f7635b422fbe6cb8d1d99d1235579a6ac8024c13d743efa6847/transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "Collecting accelerate==0.25.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f7/fc/c55e5a2da345c9a24aa2e1e0f60eb2ca290b6a41be82da03a6d4baec4f99/accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from transformers==4.36.2) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from transformers==4.36.2) (0.34.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from transformers==4.36.2) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from transformers==4.36.2) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from transformers==4.36.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from transformers==4.36.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from transformers==4.36.2) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from transformers==4.36.2) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from transformers==4.36.2) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from transformers==4.36.2) (4.67.1)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from accelerate==0.25.0) (7.0.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from accelerate==0.25.0) (2.3.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (1.1.5)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.25.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.25.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.25.0) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.25.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.25.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.25.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.25.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.25.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.25.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.25.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.25.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.25.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.25.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.25.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.25.0) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.25.0) (12.9.86)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate==0.25.0) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from requests->transformers==4.36.2) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from requests->transformers==4.36.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from requests->transformers==4.36.2) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from requests->transformers==4.36.2) (2025.7.14)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate==0.25.0) (1.3.0)\n",
      "Installing collected packages: transformers, accelerate\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [accelerate]2\u001b[0m [accelerate]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-0.25.0 transformers-4.36.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.36.2 accelerate==0.25.0 -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8b7af4e-5176-4cfd-a9d8-83497cd2c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ad35e73-8e8e-450c-8846-5b3064327996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7691aaa5-4146-4934-aca8-392034f18863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ce975cc-51b0-4b6b-b7a1-71159227b388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 2,\n",
       " 'text': \"As far as Starbucks go, this is a pretty nice one.  The baristas are friendly and while I was here, a lot of regulars must have come in, because they bantered away with almost everyone.  The bathroom was clean and well maintained and the trash wasn't overflowing in the canisters around the store.  The pastries looked fresh, but I didn't partake.  The noise level was also at a nice working level - not too loud, music just barely audible.\\\\n\\\\nI do wish there was more seating.  It is nice that this location has a counter at the end of the bar for sole workers, but it doesn't replace more tables.  I'm sure this isn't as much of a problem in the summer when there's the space outside.\\\\n\\\\nThere was a treat receipt promo going on, but the barista didn't tell me about it, which I found odd.  Usually when they have promos like that going on, they ask everyone if they want their receipt to come back later in the day to claim whatever the offer is.  Today it was one of their new pastries for $1, I know in the summer they do $2 grande iced drinks with that morning's receipt.\\\\n\\\\nOverall, nice working or socializing environment.  Very friendly and inviting.  It's what I've come to expect from Starbucks, so points for consistency.\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edac8c3f-9f33-4cf7-a50e-44e352ce940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7b90818-75dc-4e47-a1b2-ecac7443dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f6575d2-227a-4805-99d4-17096d69985a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 star</td>\n",
       "      <td>I ate here on Saturday night and it was a really disappointing experience. Our waiter was a dick (wish I knew his name so you could avoid his douche-ness) and the menu was less than innovative. Watching Bobby on TV, you'd think his dishes would have a little more spunk and creativity involved but it was all just blah. \\n\\n-Goat Cheese 'Queso Fundido': Very good, but then again how hard is it to screw up melted cheese? Not super creative or special. \\n-Chile Relleno: 'cornmeal crust' was very dry, pepper was undercooked and tough, sauce was only redeeming part. \\n-Coffee Rubbed Filet Mignon: If you don't like cumin, you will hate this. It's LOADED on the outside with cumin like someone dumped a whole spice jar of it on there (which I hate and wasn't mentioned or I wouldn't have ordered it). Mushroom-Ancho Chile Sauce is VERY spicy and I like spice. Between cutting off the outside to avoid choking on the cumin and not being able to eat most of the mushrooms, it was wasted. It was, however, cooked perfectly as I ordered it medium. \\n\\nWe didn't have cocktails, only wine so I can't speak about the mixed drinks. The whole experience was a total letdown. There are so many better places in Vegas... would not waste my time or money on this one again.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 star</td>\n",
       "      <td>If melted cheese on cardboard is your idea of a good pizza then this is the place for you. Seriously, I am a huge pizza fan and this place is right around the corner from me so I thought it could not be worst than Pizza Hut. Well it is, 100 times worse!\\nI was so appalled, I returned the next day because to speak to the owner and give him some feedback. Nice young guy from Russia or something but he had the arrogance to tell me his pizzas are the best, was expanding to LA and that if I did not like them I could take my business elsewhere. And that is exactly what I will do!\\nSave your money and go get yourself a decent pizza. Frozen from Smiths is better than this place.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 stars</td>\n",
       "      <td>This is one product I have paid retail for and regretted it once I found them in outlet stores and discount stores.  So, these days, I only buy Polo on a discount or eBay.  This is a huge store and probably the largest Ralph Lauren outlet I've been in. Besides men's and women's clothing, they have lots of towels, bed sheets, etc. I definitely would check this out the next time if someone on the Christmas list needs something from here.  \\n\\nI came in to browse for shorts and shirts and left empty handed.  They didn't have the style in the color I wanted.  I am still traumatized by all of the pastels and pinks in men's shirts and shorts. More than a few times I thought maybe they accidentally labeled men's when it should've been women's.  Then I picked up what could've been a floor rug...a XXL men's canary yellow button down with pockets sweater. Ugh. Did someone actually pick that thing up and try it on?I could just hear his grand kids pointing and giggling, \\\"Grandpa, are you really going to wear that?\\\" But it was still worth it to browse here if you're in the area.  \\n\\nOverall, I think their stuff is comfortable and lasts. But I'm getting more and more partial to synthetic fabrics instead of their totally cotton items.  I end up having to iron to have their all cotton stuff and all wool pants dry cleaned. How cool is it to pull a pair of synthetic pants out of the dryer with ho wrinkles, crease in place, and soft enough to wear all day.  Not too much of that stuff at Ralph Lauren.  But I still like their polo shirts and proud that I don't buy retail.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 stars</td>\n",
       "      <td>We have been going to this Olive Garden since it opened. I guess what bothers me most about Olive Garden is that every time I find a dish I really like, they remove it from the menu. That is true of all OG's not just this location. \\n\\nOn this night, the wait was approximately 10 minutes at 7:44 pm. We had wonderful service (wish I would have noted her name) and she made some recommendations for me when she over heard my disappointment  in losing my favorite dish. I settled on the bruschetta and pesto salmon with crab risotto. It was tasty and cooked well. The salad is always good bit our breadsticks were hard and almost tasted old which is not usual. Overall, Olive Garden provides a solid meal. Is it the best no but it's ok for chain food and we will always go back just for shear ease and proximity.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 stars</td>\n",
       "      <td>Has a good selection of vegetarian options.\\n\\nThe best part of the store is the deli.\\n\\nThe rest I found overpriced.  I joined and am happy I did.\\n\\nI am used to the CO-OP's in Vermont and for some reason this location didn't match up to Vermont CO-OP's.\\n\\nAlso, prices on many things are pretty high which surprised me.  I don't mind spending extra money for good quality of food but I purchased a whole chicken for $12.00-yes I know it is organic and cage free and all but I can get one at another market for like $5.00.  Also, I spend 7.00 on orange juice which I regretted after leaving the store.\\n\\nI am glad it is nearby though and the staff is very nice and knowledgeable.\\n\\nA great place to pick up lunch or dindin from the salad bar.  Also, they have a great selection of granola/rice and pasta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3 stars</td>\n",
       "      <td>We came here during the burning show girl event. We wrongfully assumed that First Friday took place on Fremont St so we had cab it to the Art District. We got there in time for the event but was a bit disappointed that the replica didn't even look like a show girl ! I was imagining that scene from the old 80's movie \\\"The Legend of Billy Jean where they burn a big replica of Billie Jean with Pat Benatar singing in the back round \\\"We will be invincible\\\". My imagination was fizzled when I saw the big heap of wood. People were getting antsy waiting for it to burn ...they kept chanting \\\"The roof ...the roof is on fire ...we don't need no water let the motherf%#@er burn! When it finally burned it was okay. \\n\\nThis event is mainly for adults and teens I didn't see too many little kids. I don't think it would be a good idea to bring little kids here because there are a lot of drunk people stumbling around. If you want to blend in don't wear bright yellow like me. Practically everyone was wearing black except for other people wearing wedding dreses, antlers and stuff. \\n\\nI enjoyed going into the houses that were set up as mini art galleries . There is a lot of talented artists in Vegas and it's nice to know that they have a place to display their work. \\n\\nFirst Friday kind of reminds me of the weekly street fair they have in Palm Springs minus the family friendly vibe. I think this can grow into something great with time and community support!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2 star</td>\n",
       "      <td>Excellent pedicure. One of the best I've ever gotten. The guy who did my pedicure is named Eric. However, my fill was not good. It is thick and not shaped well, and very rushed. My polish job was atrocious. The nail polish needed thinner, which the tech (I think her name is Judy) neglected. The nail design I asked for is very simple, but the tech did not even give it a fair shot. Overall my nails look sloppy, like a teenager did them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2 star</td>\n",
       "      <td>The wait time is terrible. Went in for one shot and ended up waiting for a little over an hour. The real skinny dark brown hair front desk receptionist is rude. I told her I was ready to check out then she says wait until I finish doing what I'm doing and never got back to me. The other lady is much more professional you to take notes and be more professional.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3 stars</td>\n",
       "      <td>Its an alright hotel. I was really only in the room to sleep and shower but the shower was so nasty. Paint peeling everywhere and it doesn't look like they actually clean the rooms. The carpet was dirty, doesn't even look like they vacuum because there was old food and stuff on the floor. Not pleasant. On the plus side, the front staff was really nice. We asked them to call a cab and they always did with no attitude. The room was huge! Had a huge living room and bedroom. The bathroom was spacious and the outside was beautiful. The pools were huge and the grass was green. Its a very nice and big hotel from the outside. The rooms just need a little bit more attention and it will definitely be a 4-5 star hotel. Its right across from the hard rock hotel and its a nice location. CVS at the corner and the strip is only like a 15min walk. Very convenient but like I said they just need more work on the rooms. I would stay again but I would make sure to ask for a renovated room.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2 star</td>\n",
       "      <td>I didn't like this place too much. Let me start with the food it was tasteless! There was a 50 min wait Not Worth IT!.\\n\\nI don't want to write too much about this place because it was not a fun experience. Vegas has much better places!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bec0571-191a-4c64-8335-a137d7e76889",
   "metadata": {},
   "source": [
    "# 预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0daf2e7-1089-43c8-8aeb-71ebe54c7fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/aistudy3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/root/miniconda3/envs/aistudy3/lib/python3.11/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89062d5cdf5249ebb97bdf958f2dec07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d3d0998-e462-4e0f-bab5-71ea9efbd387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 star</td>\n",
       "      <td>I cant say that I really enjoyed having lunch here today.  The sushi was so so.  The mushroom tempura was actually pretty tasty, everything else, not so much.\\n\\nI never really pay attention to the prices when I eat sushi, so I can't tell you how expensive it was.  I can tell you this - I have had better.  I think this is the first time I have had sushi that I couldnt actually taste the fish in the heavy sauces that were used.\\n\\nThe tea was really good, I didnt have to add sugar to it, which is not the norm for me.  I didnt have any drinks, which I should have, because I was already having a horrible day.\\n\\nKind of disappointing, I had been looking forward to this place since I saw them putting it in a while back.  Probably wont go back.</td>\n",
       "      <td>[101, 146, 1169, 1204, 1474, 1115, 146, 1541, 4927, 1515, 5953, 1303, 2052, 119, 1109, 28117, 5933, 1108, 1177, 1177, 119, 1109, 25590, 21359, 8223, 4084, 1108, 2140, 2785, 27629, 13913, 117, 1917, 1950, 117, 1136, 1177, 1277, 119, 165, 183, 165, 183, 2240, 1309, 1541, 2653, 2209, 1106, 1103, 7352, 1165, 146, 3940, 28117, 5933, 117, 1177, 146, 1169, 112, 189, 1587, 1128, 1293, 5865, 1122, 1108, 119, 146, 1169, 1587, 1128, 1142, 118, 146, 1138, 1125, 1618, 119, 146, 1341, 1142, 1110, 1103, 1148, 1159, 146, 1138, 1125, 28117, 5933, 1115, 146, 1577, 1204, 2140, 5080, 1103, 3489, ...]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(tokenized_datasets[\"train\"], num_examples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c1e5fa-3e32-49ca-b728-c7de3ba698fa",
   "metadata": {},
   "source": [
    "# 数据抽样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d850f39b-f726-4e1f-a3b7-ffaa36564210",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01dbf57-1e3e-476f-85a7-a83fe971169f",
   "metadata": {},
   "source": [
    "# 微调训练配置\n",
    "# 加载 BERT 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac8d9c84-6dd2-48d4-8841-59143f69835a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/aistudy3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/root/miniconda3/envs/aistudy3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f640618-31b1-4f9f-abb2-9176480e5385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())  # 检查是否支持 GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9ab129-d5f1-4ee7-89ec-1aabf4fd67d5",
   "metadata": {},
   "source": [
    "# 训练超参数（TrainingArguments）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73153677-c751-4255-a24b-0a4cee75c2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "model_dir = \"models/bert-base-cased-finetune-yelp\"\n",
    "\n",
    "# logging_steps 默认值为500，根据我们的训练数据和步长，将其设置为100\n",
    "training_args = TrainingArguments(output_dir=model_dir,\n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  num_train_epochs=5,\n",
    "                                  logging_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82703ff4-3af4-4e01-b35a-1bebf2cb0d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=models/bert-base-cased-finetune-yelp/runs/Jul26_15-53-05_LZ-PC,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=100,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=5,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "output_dir=models/bert-base-cased-finetune-yelp,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=models/bert-base-cased-finetune-yelp,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 完整的超参数配置\n",
    "print(training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11daca92-63ff-4306-bd91-72303ba9ea13",
   "metadata": {},
   "source": [
    "# 训练过程中的指标评估（Evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "639a246e-5eac-45bd-8758-d3841427acdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (0.4.5)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from evaluate) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from evaluate) (2.3.2)\n",
      "Requirement already satisfied: dill in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from evaluate) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from evaluate) (0.34.1)\n",
      "Requirement already satisfied: packaging in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (21.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.14)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2025.7.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce7e3630-106f-414c-80ad-7ff758ca02e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from scikit-learn) (2.3.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /root/miniconda3/envs/aistudy3/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0417544-db36-4726-a4b3-e1cdbf6266ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7d0f7e0-5fc1-4d42-8ff9-e724bfafc83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4919838a-9603-4335-8242-bd8ac7cb27de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    evaluation_strategy=\"epoch\", \n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d0bedf-2c1a-4098-8ae1-6aaa407c043b",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b15d5ea6-0cb0-4cc5-afd9-1de484b50251",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b85e938-5e74-4f95-96d2-cf168eea63b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jul 26 15:53:18 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.133.07             Driver Version: 572.83         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080        On  |   00000000:0B:00.0  On |                  N/A |\n",
      "| 32%   43C    P2            109W /  320W |    2452MiB /  10240MiB |     12%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A              39      G   /Xwayland                             N/A      |\n",
      "|    0   N/A  N/A             422      C   /python3.11                           N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01b19d04-ff89-4758-a8de-f845c79ba035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [189/189 2:14:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.223300</td>\n",
       "      <td>1.054482</td>\n",
       "      <td>0.546000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.922700</td>\n",
       "      <td>0.980886</td>\n",
       "      <td>0.584000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.656900</td>\n",
       "      <td>0.999710</td>\n",
       "      <td>0.609000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=189, training_loss=0.9707289801703559, metrics={'train_runtime': 8054.1038, 'train_samples_per_second': 0.372, 'train_steps_per_second': 0.023, 'total_flos': 789354427392000.0, 'train_loss': 0.9707289801703559, 'epoch': 3.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e6a66-44b5-445f-826f-81d61f5f4953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
